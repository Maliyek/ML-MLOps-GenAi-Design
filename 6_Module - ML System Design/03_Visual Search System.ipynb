{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48702a5a",
   "metadata": {},
   "source": [
    "# Visual Search System\n",
    "\n",
    "\n",
    "https://in.pinterest.com/pin/495466396524160580/visual-search/?x=85&y=596&w=177&h=74&cropSource=6&imageSignature=bac31a3502b70a08d53a9eae4179145f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66117f06",
   "metadata": {},
   "source": [
    "## Frame the problem as an ML Assignment\n",
    "\n",
    "\n",
    "ML Objective \n",
    "\n",
    "- accurately retrieve images that are visually similar to the image the user is searching for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069dcc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query image  ----------> visual search system ----------> multiple similar images\n",
    "\n",
    "input                                                       output(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54c4327",
   "metadata": {},
   "source": [
    "### choose the right ML category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b433cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking problem\n",
    "- recommendation systems\n",
    "- search engine\n",
    "- document retrieval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be90369",
   "metadata": {},
   "outputs": [],
   "source": [
    "representation learning\n",
    "- embeddings vector -> its a vector representation of image\n",
    "\n",
    "|\n",
    "|             x\n",
    "| x           |\n",
    "|    x    x   |\n",
    "|  x__x_______|       \n",
    "|__________________\n",
    "\n",
    "\n",
    "n-dimensional space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2ec185",
   "metadata": {},
   "outputs": [],
   "source": [
    "dog image ------->           [0.1, 0.8, -1, 0.6, 0]\n",
    "std = 1, mean = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffb1c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "How to rank images using representation learning?\n",
    "\n",
    "- embedding vector\n",
    "- similarity scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f343261",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6562dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data Engineering\n",
    "\n",
    "- Images\n",
    "- Users\n",
    "- User-image interations\n",
    "\n",
    "\n",
    "- images\n",
    "\n",
    "id, userid, upload time, image tags(labels)\n",
    "                         (lion,animal)\n",
    "                         (pasta, food, kitchen)\n",
    "                         (child, family, party)\n",
    "\n",
    "\n",
    "- users\n",
    "\n",
    "id, username, age, gender, city, country, email\n",
    "\n",
    "\n",
    "\n",
    "- user-image interations\n",
    "\n",
    "userid, query image id, displayed image id, position in the results list, interation type, location, timestamp \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be481be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature engineering\n",
    "\n",
    "operations of image preprocessing\n",
    "\n",
    "- resizing - (224 x 224)\n",
    "- scaling - range of 0 and 1\n",
    "- consistent color mode -> RGB or CMYK(cyan, magenta, yellow and black(k))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e490f334",
   "metadata": {},
   "source": [
    "# Model development\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c8500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model selection\n",
    "- neural networks are best for unstructured data\n",
    "\n",
    "what type of neural network architectures should we use?\n",
    "- CNN based architectures -> ResNet\n",
    "- transformer based - ViT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cd8f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model training\n",
    "- the model must learn representations(embeddings)\n",
    "\n",
    "constructive training\n",
    "\n",
    "dog  ---> snake, dog, house, lion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6b76f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "construct dataset\n",
    "\n",
    "- use human judgment\n",
    "- use intraction data such as user clicks -> there can be noisy data\n",
    "- artificially create a similar image from the query image (data agumentation) \n",
    "self-supervision - SimCLR\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d61a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "choosing a loss function\n",
    "\n",
    "- compute similarities -> query images and other images -> dot product, cosine similarity, \n",
    "                       - euclidean distance -> it will perform poor on high dimentional data\n",
    "                       - curse of dimensionality\n",
    "\n",
    "- softmax -> compute distance -> 0 to 1\n",
    "\n",
    "- cross entropy - how close the predicted probabilities between negative and positive images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d78a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation\n",
    "\n",
    "offline metrics -> \n",
    "- precision\n",
    "- recall\n",
    "- mean average precision\n",
    "\n",
    "online metrics ->\n",
    "- click through rate(CTR) - how often users click on the displayed items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1f46f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do we use the vector representation on geo data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa91a195",
   "metadata": {},
   "source": [
    "# create a in-depth architecture based on the above information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a863e24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

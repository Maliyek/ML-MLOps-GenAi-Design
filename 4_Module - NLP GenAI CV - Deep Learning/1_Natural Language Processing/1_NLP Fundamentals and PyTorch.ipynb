{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c2c3e42",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "https://blog.paperspace.com/pytorch-101-understanding-graphs-and-automatic-differentiation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3796f529",
   "metadata": {},
   "outputs": [],
   "source": [
    "- context\n",
    "- intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3c3365",
   "metadata": {},
   "outputs": [],
   "source": [
    "- pytorch - deep learning framework\n",
    "- nlp fundamental methods to understand text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59efb930",
   "metadata": {},
   "source": [
    "# Bag of Words\n",
    "\n",
    "<img src='n1.png' />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaf9fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag of words representation\n",
    "\n",
    "the cat sat on the mat  -> [2,1,0,1,1,1]\n",
    "the dog sat on the cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7c59d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a84ecf8",
   "metadata": {},
   "source": [
    "# Sequential Representation\n",
    "\n",
    "<img src='n2.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718c8184",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff3a84d8",
   "metadata": {},
   "source": [
    "# PyTorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f244a9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "- it have tensors(data structure) with hardware accelerations (GPUs)\n",
    "- dynamic computational graphs(data structures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89a4a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "int -> 2 bytes (16 bits)\n",
    "\n",
    "int a = 10;\n",
    "\n",
    "float a = 10.65; -> 4 bytes(32 bits)\n",
    "\n",
    "\n",
    "Neural Network\n",
    "- forward pass \n",
    "- backward pass\n",
    "\n",
    "A-> B\n",
    "|\n",
    "C-> X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3542bf1",
   "metadata": {},
   "source": [
    "# Tensors\n",
    "\n",
    "<img src='n3.png' />\n",
    "\n",
    "<img src='Tensors.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52bb4015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa143380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,2])\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09446007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,2])\n",
    "y = torch.tensor([3,4])\n",
    "\n",
    "print(x * y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eae664a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [5, 3],\n",
      "        [0, 4]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1,2], [5,3], [0,4]])\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b46bd39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2)\n"
     ]
    }
   ],
   "source": [
    "print(x[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d6cc050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(x[0][1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93b298aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15e1f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "670941b1",
   "metadata": {},
   "source": [
    "# Neural Network in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8564ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0e91402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe2c475c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 28x28 -> 784 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57c0b0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77b38246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(np.reshape(df.values[0][1:], (28,28)))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63e4a60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "train_labels = train['label'].values\n",
    "train = train.drop('label', axis=1).values.reshape(len(train), 1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f34969fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor(train.astype(float))\n",
    "y = torch.Tensor(train_labels).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ceb5d383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the classifier\n",
    "\n",
    "class MNISTClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 392)\n",
    "        self.fc2 = nn.Linear(392, 196)\n",
    "        self.fc3 = nn.Linear(196, 98)\n",
    "        self.fc4 = nn.Linear(98, 10)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)                 # doubt\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4359a34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTClassifier()\n",
    "\n",
    "loss_function = nn.NLLLoss()\n",
    "opt = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e50b53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] Loss: 6.6796\n",
      "Epoch [2/50] Loss: 3.9992\n",
      "Epoch [3/50] Loss: 2.6990\n",
      "Epoch [4/50] Loss: 2.0911\n",
      "Epoch [5/50] Loss: 1.7405\n",
      "Epoch [6/50] Loss: 1.5250\n",
      "Epoch [7/50] Loss: 1.3482\n",
      "Epoch [8/50] Loss: 1.1700\n",
      "Epoch [9/50] Loss: 1.0369\n",
      "Epoch [10/50] Loss: 0.9857\n",
      "Epoch [11/50] Loss: 0.8652\n",
      "Epoch [12/50] Loss: 0.8285\n",
      "Epoch [13/50] Loss: 0.7171\n",
      "Epoch [14/50] Loss: 0.6951\n",
      "Epoch [15/50] Loss: 0.6145\n",
      "Epoch [16/50] Loss: 0.5979\n",
      "Epoch [17/50] Loss: 0.5718\n",
      "Epoch [18/50] Loss: 0.4982\n",
      "Epoch [19/50] Loss: 0.5055\n",
      "Epoch [20/50] Loss: 0.4541\n",
      "Epoch [21/50] Loss: 0.4331\n",
      "Epoch [22/50] Loss: 0.3708\n",
      "Epoch [23/50] Loss: 0.3491\n",
      "Epoch [24/50] Loss: 0.3527\n",
      "Epoch [25/50] Loss: 0.3309\n",
      "Epoch [26/50] Loss: 0.2788\n",
      "Epoch [27/50] Loss: 0.2816\n",
      "Epoch [28/50] Loss: 0.2198\n",
      "Epoch [29/50] Loss: 0.2277\n",
      "Epoch [30/50] Loss: 0.2406\n",
      "Epoch [31/50] Loss: 0.1987\n",
      "Epoch [32/50] Loss: 0.1832\n",
      "Epoch [33/50] Loss: 0.1685\n",
      "Epoch [34/50] Loss: 0.1633\n",
      "Epoch [35/50] Loss: 0.1420\n",
      "Epoch [36/50] Loss: 0.1355\n",
      "Epoch [37/50] Loss: 0.1276\n",
      "Epoch [38/50] Loss: 0.1147\n",
      "Epoch [39/50] Loss: 0.1068\n",
      "Epoch [40/50] Loss: 0.1233\n",
      "Epoch [41/50] Loss: 0.1093\n",
      "Epoch [42/50] Loss: 0.0918\n",
      "Epoch [43/50] Loss: 0.1004\n",
      "Epoch [44/50] Loss: 0.0773\n",
      "Epoch [45/50] Loss: 0.0690\n",
      "Epoch [46/50] Loss: 0.0777\n",
      "Epoch [47/50] Loss: 0.0769\n",
      "Epoch [48/50] Loss: 0.0595\n",
      "Epoch [49/50] Loss: 0.0644\n",
      "Epoch [50/50] Loss: 0.0691\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    images = Variable(x)\n",
    "    labels = Variable(y)\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    outputs = model(images)\n",
    "    \n",
    "    loss = loss_function(outputs, labels)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    print(\"Epoch [%d/%d] Loss: %.4f\" %(epoch + 1, 50, loss.data.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8d22c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "test_labels = test['label'].values\n",
    "test = test.drop('label', axis=1).values.reshape(len(test), 1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba282145",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest = torch.Tensor(train.astype(float))\n",
    "ytest = torch.Tensor(train_labels).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65fbed80",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0de21b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-19.8444,  -0.0893,  -8.2741, -11.2113, -11.4445,  -6.5766, -14.6546,\n",
      "         -5.5649,  -2.5265, -12.1194], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1824e661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted value</th>\n",
       "      <th>True Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predicted value  True Value\n",
       "0                1         9.0\n",
       "1                0         5.0\n",
       "2                1         2.0\n",
       "3                4         4.0\n",
       "4                0         1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, predictionlabel = torch.max(preds.data, 1)\n",
    "predictionlabel = predictionlabel.tolist()\n",
    "\n",
    "predictionlabel = pd.Series(predictionlabel)\n",
    "test_labels = pd.Series(test_labels)\n",
    "\n",
    "pred_table = pd.concat([predictionlabel, test_labels], axis=1)\n",
    "pred_table.columns = ['Predicted value', 'True Value']\n",
    "\n",
    "pred_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae28f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e89c379d",
   "metadata": {},
   "source": [
    "# Word Embeddings\n",
    "\n",
    "<img src='n2.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c07925",
   "metadata": {},
   "outputs": [],
   "source": [
    "word into numerical representation(one-hot encoding)\n",
    "\n",
    "- semantic relationship\n",
    "\n",
    "cat == cat\n",
    "\n",
    "cat <==> dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f841c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47397338",
   "metadata": {},
   "source": [
    "# Global Vector for Word Embeddings\n",
    "\n",
    "https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6120c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGlove(path):\n",
    "    file = open(path, 'r', encoding='utf8')\n",
    "    model = {}\n",
    "    \n",
    "    for l in file:\n",
    "        line = l.split()\n",
    "        word = line[0]\n",
    "        value = np.array([float(val) for val in line[1:]])\n",
    "        model[word] = value\n",
    "    \n",
    "    return model\n",
    "\n",
    "glove = loadGlove('glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c93e04d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5897  , -0.55043 , -1.0106  ,  0.41226 ,  0.57348 ,  0.23464 ,\n",
       "       -0.35773 , -1.78    ,  0.10745 ,  0.74913 ,  0.45013 ,  1.0351  ,\n",
       "        0.48348 ,  0.47954 ,  0.51908 , -0.15053 ,  0.32474 ,  1.0789  ,\n",
       "       -0.90894 ,  0.42943 , -0.56388 ,  0.69961 ,  0.13501 ,  0.16557 ,\n",
       "       -0.063592,  0.35435 ,  0.42819 ,  0.1536  , -0.47018 , -1.0935  ,\n",
       "        1.361   , -0.80821 , -0.674   ,  1.2606  ,  0.29554 ,  1.0835  ,\n",
       "        0.2444  , -1.1877  , -0.60203 , -0.068315,  0.66256 ,  0.45336 ,\n",
       "       -1.0178  ,  0.68267 , -0.20788 , -0.73393 ,  1.2597  ,  0.15425 ,\n",
       "       -0.93256 , -0.15025 ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove['python']   # vector embedding for the word Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca403005",
   "metadata": {},
   "source": [
    "## How the system know that these words are similar?\n",
    "\n",
    "Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a326f8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbfb9fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.92180053]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(glove['cat'].reshape(1,-1), glove['dog'].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19c7f6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19825255]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(glove['cat'].reshape(1,-1), glove['piano'].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a41e0508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7839043]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(glove['king'].reshape(1,-1), glove['queen'].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f97db29",
   "metadata": {},
   "source": [
    "# n-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e90d246",
   "metadata": {},
   "outputs": [],
   "source": [
    "the cat sat on the dog\n",
    "the dog sat on the cat\n",
    "\n",
    "\n",
    "bag of words representation of the above sentences are identical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126bb093",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi-gram\n",
    "        - the cat, the dog, cat sat, dog sat, sat on, on the\n",
    "1       -    1       1          1       0      1         1\n",
    "2       -    1       1          0       1      1         1\n",
    "\n",
    "n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640ec45f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f63ffe1",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1f3429a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d760e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'is', 'a', 'single', 'sentence', '.']\n"
     ]
    }
   ],
   "source": [
    "text = 'this is a single sentence.'\n",
    "\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39e3e309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'is', 'a', 'single', 'sentence']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_punctuation = [word.lower() for word in tokens if word.isalpha()]\n",
    "no_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d1eee79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this is the first sentence.', 'this is the second sentence.', 'this is the document.']\n"
     ]
    }
   ],
   "source": [
    "text = 'this is the first sentence. this is the second sentence. this is the document.'\n",
    "\n",
    "print(sent_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f11e8d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is', 'the', 'first', 'sentence', '.'], ['this', 'is', 'the', 'second', 'sentence', '.'], ['this', 'is', 'the', 'document', '.']]\n"
     ]
    }
   ],
   "source": [
    "print([word_tokenize(sentence) for sentence in sent_tokenize(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aef6fe6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his']\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "print(stop_words[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7871a285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['first', 'sentence', '.', 'second', 'sentence', '.', 'document', '.']\n"
     ]
    }
   ],
   "source": [
    "text = 'this is the first sentence. this is the second sentence. this is the document.'\n",
    "\n",
    "tokens = [token for token in word_tokenize(text) if token not in stop_words]\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a795c78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06f50791",
   "metadata": {},
   "source": [
    "# POS(Parts Of Speech) tagging and chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a8546c",
   "metadata": {},
   "outputs": [],
   "source": [
    "the big dog is sleeping on the bed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "219c48f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading averaged_perceptron_tagger: <urlopen error\n",
      "[nltk_data]     [WinError 10060] A connection attempt failed because\n",
      "[nltk_data]     the connected party did not properly respond after a\n",
      "[nltk_data]     period of time, or established connection failed\n",
      "[nltk_data]     because connected host has failed to respond>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a6ce5c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f6ea4bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"the big dog is sleeping on the bed.\"\n",
    "\n",
    "# token = word_tokenize(text)\n",
    "\n",
    "# print(pos_tag(token))\n",
    "\n",
    "# error in the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b775a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.help.upenn_tagset('VBG')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f44b55",
   "metadata": {},
   "source": [
    "# TF-IDF\n",
    "\n",
    "Term Frequency - Inverse Document Frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdf7164",
   "metadata": {},
   "outputs": [],
   "source": [
    "this is a small giraffe\n",
    "                   |\n",
    "                weight to rare words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3549e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829ea8bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb13c2ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01409eb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8806477",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

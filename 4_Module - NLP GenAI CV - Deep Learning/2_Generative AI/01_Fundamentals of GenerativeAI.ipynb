{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b2ab490",
   "metadata": {},
   "source": [
    "# Generative AI\n",
    "\n",
    "GPT-3 (Large Language Model) = OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c6c16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Natural Language Processing - Rule based modeling of human language.\n",
    "\n",
    "- context\n",
    "- intent\n",
    "\n",
    "tool\n",
    "- Machine Learning - Needs Feature Engineering, Structured data(rows and columns)\n",
    "- Deep Learning - Dont need feature engineering, Unstructured Data(text, images, videos, audios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe06663e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Deep Learning Milestones\n",
    "- Artificial Neurons\n",
    "- pre-trained models(GPT-3) - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a824ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "NLP Real-world examples\n",
    "- Spam Detection\n",
    "- Machine Translation(Google Translate)\n",
    "- Virtual Assistant & chatbots (Alexa, Siri, Google Assistant)\n",
    "- Social Media sentiment analysis\n",
    "- Text Summarization\n",
    "- Semantic Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5af5a4",
   "metadata": {},
   "source": [
    "# Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e85e36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Simple laguage model - predicting the next word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddd88ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "autocomplete - good -> night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2407f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Language models -> one NLP task -> text generation, summarization or classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58d00a5",
   "metadata": {},
   "source": [
    "# Generative Pre-Trained Transformer (GPT-3)\n",
    "\n",
    "\n",
    "## Generative Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f49b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "Generative modeling > statistical modeling(approximating the world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434b821f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pre-Trained Models \n",
    "- they are trained on fundamental general tasks and later we fine-tune for different tasks.\n",
    "\n",
    "Datasets\n",
    "- Common Crawl - text data colleced over 8 years of web crawling\n",
    "- WebText2 - hight quality  web pages\n",
    "- Books1\n",
    "- Books2\n",
    "- Wikipedia\n",
    "\n",
    "93% - english data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7097d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transformer Models\n",
    "\n",
    "- huge architecture of neural networks\n",
    "\n",
    "Fundamental architecture of transformer is - sequence to sequence architecture(Seq2Seq)\n",
    "\n",
    "Seq2Seq -> \n",
    "- converting a sequence of elements(words in a sentence) into another sequence(different language)\n",
    "\n",
    "- best for translation tasks\n",
    "\n",
    "\n",
    "\n",
    "Seq2Seq - two components \n",
    "\n",
    "- encoder\n",
    "- decoder\n",
    "\n",
    "\n",
    "Transformer works on attention mechanism\n",
    "\n",
    "- Himanshu is sitting on a chair, He will take the session.\n",
    "\n",
    "- my dog is eating food, now it will go the park.\n",
    "\n",
    "\n",
    "tranformer has 2 types of attention\n",
    "- self-attention - the connection of words within a sentence\n",
    "- encoder-decoder attention \n",
    "    - the connection between words from the source sentence to words from the target sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4932c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "                              context\n",
    "hindi sentence -> Encoder  ------------>  decoder -> english sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152b5d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT-1 - 2017\n",
    "GPT-2 - 2019\n",
    "GPT-3 - 175 billion parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d5c68a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

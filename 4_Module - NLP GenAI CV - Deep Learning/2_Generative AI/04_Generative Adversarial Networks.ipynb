{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72d38ede",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks\n",
    "\n",
    "https://thispersondoesnotexist.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d9efd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep learning architecture that have \n",
    "\n",
    "2 neural networks that competing against each other\n",
    "\n",
    "zero-sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163f92f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "applications\n",
    "\n",
    "- image synthesis and generation\n",
    "- image-to-image translation\n",
    "- text-to-image synthesis\n",
    "- style transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3905cfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - Generative\n",
    "- generative\n",
    "- discriminative\n",
    "\n",
    "2 - Adversarial\n",
    "dynamics of both the networks or relationship between both the networks\n",
    "\n",
    "3 - Networks\n",
    "deep neural networks are used (convolutional and deconvolutional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fd21c0",
   "metadata": {},
   "source": [
    "<img src='g1.jpg' /> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f490662",
   "metadata": {},
   "outputs": [],
   "source": [
    "- the generator tries to maximize the probability of the discriminator making mistakes\n",
    "(maximizing the loss of discriminator)\n",
    "\n",
    "- the discriminator estimates the probability that the sample is got from the training data \n",
    "  not from the generator\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d96373",
   "metadata": {},
   "source": [
    "<img src='g2.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85643549",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dx -> prediction of discriminator on the real data\n",
    "\n",
    "1-DGz -> prediction of discriminator on the fake data(generated by generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3ec5e3",
   "metadata": {},
   "source": [
    "<img src='g3.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcafab26",
   "metadata": {},
   "outputs": [],
   "source": [
    "types of GANs\n",
    "\n",
    "1 - Vanila GAN\n",
    "2 - Conditional GAN\n",
    "3 - Deep Convolutional GAN\n",
    "4 - Super Resolution GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bbce92",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dc1c394",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9447658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self,latent_dim, img_shape):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(128,784),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.img_shape = img_shape\n",
    "    \n",
    "    # view() reshapes the tensor without copying memory, similar to numpy's reshape().\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), *self.img_shape)\n",
    "        return img\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_shape):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(784, 128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(128,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.img_shape = img_shape\n",
    "    \n",
    "    # if there is any situation that you don't know how many rows you want \n",
    "    # but are sure of the number of columns, then you can specify this with a -1. \n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        validity = self.model(img_flat)\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dac9c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "img_shape = (1,28,28)\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "lr = 0.0002\n",
    "\n",
    "generator = Generator(latent_dim, img_shape)\n",
    "discriminator = Discriminator(img_shape)\n",
    "\n",
    "adversarial_loss = nn.BCELoss() # Binary Cross Entropy\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=lr)\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c16d2576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:06<00:00, 1468324.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 26005945.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:04<00:00, 408266.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 4513273.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "mnist_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "dataloader = DataLoader(mnist_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc08f442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "        batch_size = imgs.shape[0]\n",
    "        \n",
    "        valid = torch.ones(batch_size, 1)\n",
    "        fake = torch.zeros(batch_size, 1)\n",
    "        \n",
    "        # generator\n",
    "        optimizer_G.zero_grad()\n",
    "        z = torch.randn(batch_size, latent_dim)\n",
    "        gen_imgs = generator(z)\n",
    "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.stop()\n",
    "        \n",
    "        # discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "        real_loss = adversarial_loss(discriminator(imgs), valid)\n",
    "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss)/2\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            print(f\"Epoch {epoch}/{epochs} [D loss: {d_loss.item()}] [G loss: {g_loss.item()}]\")\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            with torch.no_grad():\n",
    "                z = torch.randn(25, latent_dim)\n",
    "                gen_imgs = generator(z)\n",
    "                gen_imgs = gen_imgs.view(-1, 28, 28).numpy()\n",
    "\n",
    "                plt.figure(figsize=(5,5))\n",
    "                for k in range(gen_imgs.shape[0]):\n",
    "                    plt.subplot(5,5,k+1)\n",
    "                    plt.imshow(gen_imgs[k], cmap='gray')\n",
    "                    plt.axis('off')\n",
    "                plt.savefig(f'gan_generated_image_{epoch}.png')\n",
    "                plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca62b417",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
